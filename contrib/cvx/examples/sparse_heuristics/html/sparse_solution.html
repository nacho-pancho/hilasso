
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN">
<html xmlns:mwsh="http://www.mathworks.com/namespace/mcode/v1/syntaxhighlight.dtd">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      -->
      <title>Computing a sparse solution of a set of linear inequalities</title>
      <meta name="generator" content="MATLAB 7.5">
      <meta name="date" content="2008-05-23">
      <meta name="m-file" content="sparse_solution"><style>

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head>
   <body>
      <div class="content">
         <h1>Computing a sparse solution of a set of linear inequalities</h1><pre class="codeinput"><span class="comment">% Section 6.2, Boyd &amp; Vandenberghe "Convex Optimization"</span>
<span class="comment">% "Just relax: Convex programming methods for subset selection</span>
<span class="comment">%  and sparse approximation" by J. A. Tropp</span>
<span class="comment">% Written for CVX by Almir Mutapcic - 02/28/06</span>
<span class="comment">%</span>
<span class="comment">% We consider a set of linear inequalities A*x &lt;= b which are</span>
<span class="comment">% feasible. We apply two heuristics to find a sparse point x that</span>
<span class="comment">% satisfies these inequalities.</span>
<span class="comment">%</span>
<span class="comment">% The (standard) l1-norm heuristic for finding a sparse solution is:</span>
<span class="comment">%</span>
<span class="comment">%   minimize   ||x||_1</span>
<span class="comment">%       s.t.   Ax &lt;= b</span>
<span class="comment">%</span>
<span class="comment">% The log-based heuristic is an iterative method for finding</span>
<span class="comment">% a sparse solution, by finding a local optimal point for the problem:</span>
<span class="comment">%</span>
<span class="comment">%   minimize   sum(log( delta + |x_i| ))</span>
<span class="comment">%       s.t.   Ax &lt;= b</span>
<span class="comment">%</span>
<span class="comment">% where delta is a small threshold value (determines what is close to zero).</span>
<span class="comment">% We cannot solve this problem since it is a minimization of a concave</span>
<span class="comment">% function and thus it is not a convex problem. However, we can apply</span>
<span class="comment">% a heuristic in which we linearize the objective, solve, and re-iterate.</span>
<span class="comment">% This becomes a weighted l1-norm heuristic:</span>
<span class="comment">%</span>
<span class="comment">%   minimize sum( W_i * |x_i| )</span>
<span class="comment">%       s.t. Ax &lt;= b</span>
<span class="comment">%</span>
<span class="comment">% which in each iteration re-adjusts the weights W_i based on the rule:</span>
<span class="comment">%</span>
<span class="comment">%   W_i = 1/(delta + |x_i|), where delta is a small threshold value</span>
<span class="comment">%</span>
<span class="comment">% This algorithm is described in papers:</span>
<span class="comment">% "An Affine Scaling Methodology for Best Basis Selection"</span>
<span class="comment">%  by B. D. Rao and K. Kreutz-Delgado</span>
<span class="comment">% "Portfolio optimization with linear and &iuml;&not;?xed transaction costs"</span>
<span class="comment">%  by M. S. Lobo, M. Fazel, and S. Boyd</span>

<span class="comment">% fix random number generator so we can repeat the experiment</span>
seed = 0;
randn(<span class="string">'state'</span>,seed);
rand(<span class="string">'state'</span>,seed);

<span class="comment">% the threshold value below which we consider an element to be zero</span>
delta = 1e-8;

<span class="comment">% problem dimensions (m inequalities in n-dimensional space)</span>
m = 100;
n = 50;

<span class="comment">% construct a feasible set of inequalities</span>
<span class="comment">% (this system is feasible for the x0 point)</span>
A  = randn(m,n);
x0 = randn(n,1);
b  = A*x0 + rand(m,1);

<span class="comment">% l1-norm heuristic for finding a sparse solution</span>
fprintf(1, <span class="string">'Finding a sparse feasible point using l1-norm heuristic ...'</span>)
cvx_begin
  variable <span class="string">x_l1(n)</span>
  minimize( norm( x_l1, 1 ) )
  subject <span class="string">to</span>
    A*x_l1 &lt;= b;
cvx_end

<span class="comment">% number of nonzero elements in the solution (its cardinality or diversity)</span>
nnz = length(find( abs(x_l1) &gt; delta ));
fprintf(1,[<span class="string">'\nFound a feasible x in R^%d that has %d nonzeros '</span> <span class="keyword">...</span>
           <span class="string">'using the l1-norm heuristic.\n'</span>],n,nnz);

<span class="comment">% iterative log heuristic</span>
NUM_RUNS = 15;
nnzs = [];
W = ones(n,1); <span class="comment">% initial weights</span>

disp([char(10) <span class="string">'Log-based heuristic:'</span>]);
<span class="comment">% cvx_quiet(true);</span>
<span class="keyword">for</span> k = 1:NUM_RUNS
  cvx_begin <span class="string">quiet</span>
    variable <span class="string">x_log(n)</span>
    minimize( sum( W.*abs(x_log) ) )
    subject <span class="string">to</span>
      A*x_log &lt;= b;
  cvx_end

  <span class="comment">% display new number of nonzeros in the solution vector</span>
  nnz = length(find( abs(x_log) &gt; delta ));
  nnzs = [nnzs nnz];
  fprintf(1,<span class="string">'   found a solution with %d nonzeros...\n'</span>, nnz);

  <span class="comment">% adjust the weights and re-iterate</span>
  W = 1./(delta + abs(x_log));
<span class="keyword">end</span>
<span class="comment">% cvx_quiet(false);</span>

<span class="comment">% number of nonzero elements in the solution (its cardinality or diversity)</span>
nnz = length(find( abs(x_log) &gt; delta ));
fprintf(1,[<span class="string">'\nFound a feasible x in R^%d that has %d nonzeros '</span> <span class="keyword">...</span>
           <span class="string">'using the log heuristic.\n'</span>],n,nnz);

<span class="comment">% plot number of nonzeros versus iteration</span>
plot(1:NUM_RUNS, nnzs, [1 NUM_RUNS],[nnzs(1) nnzs(1)],<span class="string">'--'</span>);
axis([1 NUM_RUNS 0 n])
xlabel(<span class="string">'iteration'</span>), ylabel(<span class="string">'number of nonzeros (cardinality)'</span>);
legend(<span class="string">'log heuristic'</span>,<span class="string">'l1-norm heuristic'</span>,<span class="string">'Location'</span>,<span class="string">'SouthEast'</span>)
</pre><pre class="codeoutput">Finding a sparse feasible point using l1-norm heuristic ... 
Calling SDPT3: 200 variables, 100 equality constraints
------------------------------------------------------------

 num. of constraints = 100
 dim. of socp   var  = 100,   num. of socp blk  = 50
 dim. of linear var  = 100
*******************************************************************
   SDPT3: Infeasible path-following algorithms
*******************************************************************
 version  predcorr  gam  expon  scale_data
    NT      1      0.000   1        0    
it pstep dstep pinfeas dinfeas  gap      mean(obj)   cputime
-------------------------------------------------------------------
 0|0.000|0.000|1.5e+01|1.5e+01|1.3e+05| 1.153213e+02| 0:0:00| chol  1  1 
 1|0.607|0.203|5.7e+00|1.2e+01|9.6e+04| 1.147035e+03| 0:0:00| chol  1  1 
 2|0.527|0.755|2.7e+00|3.0e+00|4.4e+04| 1.224390e+03| 0:0:00| chol  1  1 
 3|0.783|1.000|5.9e-01|2.7e-02|1.1e+04| 7.672027e+02| 0:0:00| chol  1  1 
 4|0.933|1.000|3.9e-02|8.1e-03|1.2e+03|-2.176195e+02| 0:0:00| chol  1  1 
 5|1.000|0.960|7.9e-07|8.9e-03|2.8e+02|-3.549165e+01| 0:0:00| chol  1  1 
 6|0.842|0.872|3.2e-07|1.2e-03|5.3e+01| 3.009030e+01| 0:0:00| chol  1  1 
 7|0.590|0.753|1.4e-07|3.1e-04|3.3e+01| 3.201707e+01| 0:0:00| chol  1  1 
 8|0.864|0.581|2.2e-08|1.3e-04|1.9e+01| 3.262613e+01| 0:0:01| chol  1  1 
 9|1.000|0.553|1.2e-09|5.8e-05|1.1e+01| 3.402021e+01| 0:0:01| chol  1  1 
10|1.000|0.851|9.9e-14|8.6e-06|3.9e+00| 3.553340e+01| 0:0:01| chol  1  1 
11|0.857|0.651|2.6e-14|3.0e-06|2.2e+00| 3.565455e+01| 0:0:01| chol  1  1 
12|0.885|1.000|8.2e-14|8.2e-11|1.1e+00| 3.594403e+01| 0:0:01| chol  1  1 
13|1.000|0.971|2.8e-14|1.1e-11|2.2e-01| 3.593053e+01| 0:0:01| chol  1  1 
14|1.000|0.667|4.2e-12|5.3e-12|9.5e-02| 3.592692e+01| 0:0:01| chol  1  1 
15|0.965|0.928|4.2e-13|1.5e-12|1.7e-02| 3.593930e+01| 0:0:01| chol  1  1 
16|0.873|1.000|3.1e-13|1.0e-12|5.3e-03| 3.594086e+01| 0:0:01| chol  1  2 
17|0.920|0.980|1.4e-12|1.0e-12|5.9e-04| 3.594084e+01| 0:0:01| chol  2  2 
18|1.000|0.977|7.0e-12|1.0e-12|5.9e-05| 3.594077e+01| 0:0:01| chol  2  2 
19|0.996|0.998|2.3e-12|1.4e-12|9.1e-07| 3.594078e+01| 0:0:01|
  stop: max(relative gap, infeasibilities) &lt; 1.49e-08
-------------------------------------------------------------------
 number of iterations   = 19
 primal objective value =  3.59407774e+01
 dual   objective value =  3.59407765e+01
 gap := trace(XZ)       = 9.08e-07
 relative gap           = 1.25e-08
 actual relative gap    = 1.25e-08
 rel. primal infeas     = 2.31e-12
 rel. dual   infeas     = 1.39e-12
 norm(X), norm(y), norm(Z) = 1.7e+01, 1.6e+00, 9.9e+00
 norm(A), norm(b), norm(C) = 7.3e+01, 8.9e+01, 8.1e+00
 Total CPU time (secs)  = 1.1  
 CPU time per iteration = 0.1  
 termination code       =  0
 DIMACS: 8.0e-12  0.0e+00  5.6e-12  0.0e+00  1.2e-08  1.2e-08
-------------------------------------------------------------------
------------------------------------------------------------
Status: Solved
Optimal value (cvx_optval): +35.9408

Found a feasible x in R^50 that has 46 nonzeros using the l1-norm heuristic.

Log-based heuristic:
   found a solution with 46 nonzeros...
   found a solution with 37 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...
   found a solution with 35 nonzeros...

Found a feasible x in R^50 that has 35 nonzeros using the log heuristic.
</pre><img vspace="5" hspace="5" src="sparse_solution_01.png"> <p class="footer"><br>
            Published with MATLAB&reg; 7.5<br></p>
      </div>
      <!--
##### SOURCE BEGIN #####
%% Computing a sparse solution of a set of linear inequalities

% Section 6.2, Boyd & Vandenberghe "Convex Optimization"
% "Just relax: Convex programming methods for subset selection
%  and sparse approximation" by J. A. Tropp
% Written for CVX by Almir Mutapcic - 02/28/06
%
% We consider a set of linear inequalities A*x <= b which are
% feasible. We apply two heuristics to find a sparse point x that
% satisfies these inequalities.
%
% The (standard) l1-norm heuristic for finding a sparse solution is:
%
%   minimize   ||x||_1
%       s.t.   Ax <= b
%
% The log-based heuristic is an iterative method for finding
% a sparse solution, by finding a local optimal point for the problem:
%
%   minimize   sum(log( delta + |x_i| ))
%       s.t.   Ax <= b
%
% where delta is a small threshold value (determines what is close to zero).
% We cannot solve this problem since it is a minimization of a concave
% function and thus it is not a convex problem. However, we can apply
% a heuristic in which we linearize the objective, solve, and re-iterate.
% This becomes a weighted l1-norm heuristic:
%
%   minimize sum( W_i * |x_i| )
%       s.t. Ax <= b
%
% which in each iteration re-adjusts the weights W_i based on the rule:
%
%   W_i = 1/(delta + |x_i|), where delta is a small threshold value
%
% This algorithm is described in papers:
% "An Affine Scaling Methodology for Best Basis Selection"
%  by B. D. Rao and K. Kreutz-Delgado
% "Portfolio optimization with linear and ï¬?xed transaction costs"
%  by M. S. Lobo, M. Fazel, and S. Boyd

% fix random number generator so we can repeat the experiment
seed = 0;
randn('state',seed);
rand('state',seed);

% the threshold value below which we consider an element to be zero
delta = 1e-8;

% problem dimensions (m inequalities in n-dimensional space)
m = 100;
n = 50;

% construct a feasible set of inequalities
% (this system is feasible for the x0 point)
A  = randn(m,n);
x0 = randn(n,1);
b  = A*x0 + rand(m,1); 

% l1-norm heuristic for finding a sparse solution
fprintf(1, 'Finding a sparse feasible point using l1-norm heuristic ...')
cvx_begin
  variable x_l1(n)
  minimize( norm( x_l1, 1 ) )
  subject to
    A*x_l1 <= b;
cvx_end

% number of nonzero elements in the solution (its cardinality or diversity)
nnz = length(find( abs(x_l1) > delta ));
fprintf(1,['\nFound a feasible x in R^%d that has %d nonzeros ' ...
           'using the l1-norm heuristic.\n'],n,nnz);

% iterative log heuristic
NUM_RUNS = 15;
nnzs = [];
W = ones(n,1); % initial weights

disp([char(10) 'Log-based heuristic:']);
% cvx_quiet(true);
for k = 1:NUM_RUNS
  cvx_begin quiet
    variable x_log(n)
    minimize( sum( W.*abs(x_log) ) )
    subject to
      A*x_log <= b;
  cvx_end

  % display new number of nonzeros in the solution vector
  nnz = length(find( abs(x_log) > delta ));
  nnzs = [nnzs nnz];
  fprintf(1,'   found a solution with %d nonzeros...\n', nnz);

  % adjust the weights and re-iterate
  W = 1./(delta + abs(x_log));
end
% cvx_quiet(false);

% number of nonzero elements in the solution (its cardinality or diversity)
nnz = length(find( abs(x_log) > delta ));
fprintf(1,['\nFound a feasible x in R^%d that has %d nonzeros ' ...
           'using the log heuristic.\n'],n,nnz);

% plot number of nonzeros versus iteration
plot(1:NUM_RUNS, nnzs, [1 NUM_RUNS],[nnzs(1) nnzs(1)],'REPLACE_WITH_DASH_DASH');
axis([1 NUM_RUNS 0 n])
xlabel('iteration'), ylabel('number of nonzeros (cardinality)');
legend('log heuristic','l1-norm heuristic','Location','SouthEast')

##### SOURCE END #####
-->
   </body>
</html>